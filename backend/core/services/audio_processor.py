import os
import asyncio
import logging
import numpy as np
from time import time
from typing import AsyncIterator, List, Dict, Optional, Callable
from core.utils.ffmpeg_manager import FFmpegAudioManager, FFmpegState
from conf.model import ModelConfig
from core.services.denoising_service import DenoisingService
from core.utils.model_manager import ModelManager
from core.utils.media_processor import MediaProcessor
from core.services.speech_service import SpeechRecognitionService
from core.services.streaming_speech_service import StreamingSpeechService
from core.services.speaker_separation_service import SpeakerSeparationService

logger = logging.getLogger(__name__)

class AudioProcessor:
    """éŸ³é¢‘å¤„ç†ä¸šåŠ¡é€»è¾‘"""
    
    def __init__(self, **kwargs):
        self.model_config = ModelConfig()
        self.model_manager = ModelManager(self.model_config)
        self.speech_service = SpeechRecognitionService(self.model_manager)
        self.streaming_service = StreamingSpeechService(self.model_manager)
        self.speaker_service = SpeakerSeparationService(self.model_manager)
        self.denoising_service = DenoisingService(self.model_manager)
        self.temp_files = []  # ç”¨äºè·Ÿè¸ªä¸´æ—¶æ–‡ä»¶


        # éŸ³é¢‘å¤„ç†é…ç½®
        self.sample_rate = 16000
        self.channels =1
        self.chunk_duration = kwargs.get('chunk_duration', 5)
        
        # è®¡ç®—ç¼“å†²åŒºå‚æ•°
        self.bytes_per_sample = 2  # 16-bit PCM
        self.samples_per_chunk = int(self.sample_rate * self.chunk_duration)
        self.bytes_per_chunk = self.samples_per_chunk * self.bytes_per_sample * self.channels
        self.max_buffer_size = self.bytes_per_chunk * 10  # æœ€å¤§ç¼“å†²10ä¸ªå—
        
        # FFmpegç®¡ç†å™¨
        self.ffmpeg_manager = FFmpegAudioManager(
            sample_rate=self.sample_rate,
            channels=self.channels,
        )
        
        # çŠ¶æ€ç®¡ç† - ç®€åŒ–ä¸º3ä¸ªçŠ¶æ€
        # IDLE: åˆå§‹åŒ–å®Œæˆï¼Œæœªå¯åŠ¨
        # RUNNING: æ­£åœ¨å¤„ç†éŸ³é¢‘
        # STOPPED: å·²åœæ­¢ï¼Œå¯ä»¥è¢«æ¸…ç†
        self._state = "IDLE"
        self._state_lock = asyncio.Lock()
        
        self.pcm_buffer = bytearray()
        self.temp_files = []
        
        # å¼‚æ­¥ä»»åŠ¡ç®¡ç†
        self.transcription_queue = asyncio.Queue()
        self.ffmpeg_reader_task = None
        self.transcription_task = None
        self.watchdog_task = None
        self.all_tasks_for_cleanup = []
        
        # å›è°ƒå‡½æ•°ï¼ˆæ”¯æŒsyncå’Œasyncï¼‰
        self.on_transcription_callback: Optional[Callable] = None
        self.on_error_callback: Optional[Callable] = None

    async def create_tasks(self) -> AsyncIterator[dict]:
        """
        åˆ›å»ºå¹¶å¯åŠ¨æ‰€æœ‰å¤„ç†ä»»åŠ¡ - å¹‚ç­‰æ“ä½œ
        
        ã€LinusåŸåˆ™ã€‘ï¼š
        1. å·²ç»RUNNINGå°±è¿”å›ç°æœ‰çš„ç”Ÿæˆå™¨ï¼Œä¸åˆ›å»ºæ–°ä»»åŠ¡
        2. åªæœ‰IDLEçŠ¶æ€æ‰èƒ½å¯åŠ¨
        3. STOPPEDçŠ¶æ€è¯´æ˜å·²ç»cleanupè¿‡ï¼Œä¸èƒ½é‡ç”¨
        """
        async with self._state_lock:
            if self._state == "RUNNING":
                logger.info("AudioProcessorå·²åœ¨è¿è¡Œï¼Œå¤ç”¨ç°æœ‰ä»»åŠ¡")
                # è¿”å›ç°æœ‰çš„ç»“æœç”Ÿæˆå™¨
                return self.results_formatter()
            
            if self._state == "STOPPED":
                logger.error("AudioProcessorå·²åœæ­¢ï¼Œæ— æ³•é‡æ–°å¯åŠ¨ï¼ˆéœ€è¦åˆ›å»ºæ–°å®ä¾‹ï¼‰")
                async def error_generator():
                    yield {
                        "status": "error",
                        "message": "å¤„ç†å™¨å·²åœæ­¢ï¼Œè¯·åˆ·æ–°é¡µé¢é‡è¯•",
                        "timestamp": time()
                    }
                return error_generator()
            
            # åªæœ‰IDLEçŠ¶æ€æ‰ç»§ç»­å¯åŠ¨
            if self._state != "IDLE":
                logger.error(f"æ— æ•ˆçš„çŠ¶æ€è½¬æ¢: {self._state} -> RUNNING")
                async def error_generator():
                    yield {
                        "status": "error",
                        "message": "éŸ³é¢‘å¤„ç†å™¨çŠ¶æ€å¼‚å¸¸",
                        "timestamp": time()
                    }
                return error_generator()
        
        # å¯åŠ¨FFmpegç®¡ç†å™¨
        logger.info("å¯åŠ¨FFmpegç®¡ç†å™¨...")
        success = await self.ffmpeg_manager.start()
        if not success:
            logger.error("FFmpegç®¡ç†å™¨å¯åŠ¨å¤±è´¥")
            async def error_generator():
                yield {
                    "status": "error",
                    "message": "éŸ³é¢‘å¤„ç†å™¨å¯åŠ¨å¤±è´¥",
                    "timestamp": time()
                }
            return error_generator()
        
        # åˆ›å»ºæ‰€æœ‰å¼‚æ­¥ä»»åŠ¡
        logger.info("åˆ›å»ºå¤„ç†ä»»åŠ¡...")
        self.all_tasks_for_cleanup = []
        processing_tasks_for_watchdog = []
        
        self.transcription_task = asyncio.create_task(self.transcription_processor())
        self.all_tasks_for_cleanup.append(self.transcription_task)
        processing_tasks_for_watchdog.append(self.transcription_task)
        
        self.ffmpeg_reader_task = asyncio.create_task(self.ffmpeg_stdout_reader())
        self.all_tasks_for_cleanup.append(self.ffmpeg_reader_task)
        processing_tasks_for_watchdog.append(self.ffmpeg_reader_task)
        
        self.watchdog_task = asyncio.create_task(self.watchdog(processing_tasks_for_watchdog))
        self.all_tasks_for_cleanup.append(self.watchdog_task)
        
        # çŠ¶æ€è½¬æ¢ IDLE -> RUNNING
        async with self._state_lock:
            self._state = "RUNNING"
        
        logger.info("AudioProcessorå·²å¯åŠ¨ï¼ŒçŠ¶æ€: RUNNING")
        return self.results_formatter()

    async def process_audio(self, audio_bytes: bytes) -> bool:
        """å¤„ç†éŸ³é¢‘æ•°æ® - åªåœ¨RUNNINGçŠ¶æ€æ¥å—æ•°æ®"""
        # æ£€æŸ¥çŠ¶æ€
        async with self._state_lock:
            current_state = self._state
        
        if current_state != "RUNNING":
            logger.warning(f"AudioProcessorçŠ¶æ€ä¸º{current_state}ï¼Œæ‹’ç»éŸ³é¢‘æ•°æ®")
            return False
        
        # ç©ºæ•°æ®è¡¨ç¤ºç»“æŸ
        if not audio_bytes:
            logger.info("æ”¶åˆ°ç©ºéŸ³é¢‘æ¶ˆæ¯ï¼Œåœæ­¢FFmpegè¾“å…¥")
            await self.ffmpeg_manager.stop()
            return True

        # å¥åº·æ£€æŸ¥
        if not await self.ffmpeg_manager.health_check():
            logger.error("FFmpegå¥åº·æ£€æŸ¥å¤±è´¥ï¼Œå°è¯•é‡å¯")
            restart_success = await self.ffmpeg_manager.restart()
            if not restart_success:
                logger.error("FFmpegé‡å¯å¤±è´¥")
                return False
            
            # ç­‰å¾…ä¸€ä¸‹è®©FFmpegç¨³å®š
            await asyncio.sleep(0.1)

        # å†™å…¥éŸ³é¢‘æ•°æ®
        success = await self.ffmpeg_manager.write_data(audio_bytes)
        if not success:
            ffmpeg_state = await self.ffmpeg_manager.get_state()
            logger.error(f"å†™å…¥éŸ³é¢‘æ•°æ®å¤±è´¥ï¼ŒFFmpegçŠ¶æ€: {ffmpeg_state}")
            
            # å°è¯•é‡å¯ä¸€æ¬¡
            if ffmpeg_state == FFmpegState.FAILED:
                logger.info("å°è¯•é‡å¯FFmpeg...")
                restart_success = await self.ffmpeg_manager.restart()
                if restart_success:
                    # é‡è¯•å†™å…¥
                    success = await self.ffmpeg_manager.write_data(audio_bytes)
                    
        return success

    async def ffmpeg_stdout_reader(self):
        """FFmpeg stdoutè¯»å–å™¨ - æ¸…æ™°çš„çŠ¶æ€æ£€æŸ¥"""
        logger.info("å¼€å§‹FFmpeg stdoutè¯»å–...")
        beg = time()
        
        try:
            while True:
                # æ£€æŸ¥çŠ¶æ€
                async with self._state_lock:
                    if self._state != "RUNNING":
                        logger.info(f"çŠ¶æ€å˜ä¸º{self._state}ï¼Œåœæ­¢è¯»å–FFmpegè¾“å‡º")
                        break
                try:
                    # æ£€æŸ¥FFmpegçŠ¶æ€
                    state = await self.ffmpeg_manager.get_state()
                    if state == FFmpegState.FAILED:
                        logger.error("FFmpegå¤„äºå¤±è´¥çŠ¶æ€")
                        break
                    elif state == FFmpegState.STOPPED:
                        logger.info("FFmpegå·²åœæ­¢")
                        break
                    elif state != FFmpegState.RUNNING:
                        logger.warning(f"FFmpegçŠ¶æ€: {state}ï¼Œç­‰å¾…ä¸­...")
                        await asyncio.sleep(0.5)
                        continue
                    
                    # è®¡ç®—åŠ¨æ€ç¼“å†²åŒºå¤§å°
                    current_time = time()
                    elapsed_time = max(0.1, current_time - beg)
                    buffer_size = max(int(32000 * elapsed_time), 4096)
                    beg = current_time

                    # ä»FFmpegè¯»å–PCMæ•°æ®
                    chunk = await self.ffmpeg_manager.read_data(buffer_size)
                    
                    if not chunk:
                        # æ— æ•°æ®æ—¶çŸ­æš‚ç­‰å¾…
                        await asyncio.sleep(0.1)
                        continue
                    
                    # æ·»åŠ åˆ°PCMç¼“å†²åŒº
                    self.pcm_buffer.extend(chunk)

                    # å½“æœ‰è¶³å¤Ÿæ•°æ®æ—¶å¤„ç†
                    if len(self.pcm_buffer) >= self.bytes_per_chunk:
                        if len(self.pcm_buffer) > self.max_buffer_size:
                            logger.warning(f"PCMç¼“å†²åŒºè¿‡å¤§: {len(self.pcm_buffer) / self.bytes_per_chunk:.1f}å—")

                        # æå–éŸ³é¢‘å—å¹¶è½¬æ¢
                        pcm_chunk = self.pcm_buffer[:self.max_buffer_size]
                        self.pcm_buffer = self.pcm_buffer[self.max_buffer_size:]
                        
                        # è½¬æ¢ä¸ºnumpyæ•°ç»„
                        audio_array = self.convert_pcm_to_float(pcm_chunk)
                        
                        # æ”¾å…¥è½¬å½•é˜Ÿåˆ—
                        await self.transcription_queue.put(audio_array.copy())
                        
                except Exception as e:
                    logger.error(f"FFmpegè¯»å–é”™è¯¯: {e}")
                    await asyncio.sleep(1)
                    
        except Exception as e:
            logger.error(f"FFmpeg stdoutè¯»å–ä»»åŠ¡å¼‚å¸¸: {e}")
        finally:
            # å‘é€ç»“æŸä¿¡å·
            await self.transcription_queue.put(None)
            logger.info("FFmpeg stdoutè¯»å–ä»»åŠ¡ç»“æŸ")

    async def transcription_processor(self):
        """è½¬å½•å¤„ç†å™¨"""
        logger.info("å¼€å§‹è½¬å½•å¤„ç†...")
        
        try:
            while True:
                try:
                    # ç­‰å¾…éŸ³é¢‘æ•°æ®
                    audio_array = await self.transcription_queue.get()
                    
                    # æ£€æŸ¥ç»“æŸä¿¡å·
                    if audio_array is None:
                        logger.info("æ”¶åˆ°è½¬å½•ç»“æŸä¿¡å·")
                        self.transcription_queue.task_done()
                        break
                    
                    # å¼‚æ­¥è½¬å½•å¤„ç†
                    result = await asyncio.get_event_loop().run_in_executor(
                        None, 
                        self._transcribe_audio_array, 
                        audio_array
                    )
                    
                    # è°ƒç”¨å›è°ƒï¼ˆæ”¯æŒsyncå’Œasyncï¼‰
                    if result and self.on_transcription_callback:
                        if asyncio.iscoroutinefunction(self.on_transcription_callback):
                            await self.on_transcription_callback(result)
                        else:
                            self.on_transcription_callback(result)
                    
                    self.transcription_queue.task_done()
                    
                except Exception as e:
                    logger.error(f"è½¬å½•å¤„ç†é”™è¯¯: {e}")
                    self.transcription_queue.task_done()
                    
        except Exception as e:
            logger.error(f"è½¬å½•å¤„ç†å™¨å¼‚å¸¸: {e}")
        finally:
            logger.info("è½¬å½•å¤„ç†å™¨ç»“æŸ")

    async def watchdog(self, tasks_to_monitor):
        """ç›‘æ§å…³é”®å¤„ç†ä»»åŠ¡çš„å¥åº·çŠ¶æ€"""
        logger.info("å¯åŠ¨ä»»åŠ¡ç›‘æ§...")
        
        try:
            while True:
                # æ£€æŸ¥çŠ¶æ€
                async with self._state_lock:
                    if self._state != "RUNNING":
                        logger.info(f"çŠ¶æ€å˜ä¸º{self._state}ï¼Œåœæ­¢ç›‘æ§")
                        break
                try:
                    # æ£€æŸ¥ä»»åŠ¡çŠ¶æ€
                    for task in tasks_to_monitor:
                        if task.done():
                            exception = task.exception()
                            if exception:
                                logger.error(f"ä»»åŠ¡å¼‚å¸¸é€€å‡º: {exception}")
                            else:
                                logger.warning("ä»»åŠ¡æ„å¤–å®Œæˆ")
                    
                    # æ£€æŸ¥FFmpegçŠ¶æ€
                    ffmpeg_state = await self.ffmpeg_manager.get_state()
                    if ffmpeg_state == FFmpegState.FAILED:
                        logger.error("FFmpegå¤„äºå¤±è´¥çŠ¶æ€")
                    elif ffmpeg_state == FFmpegState.STOPPED:
                        # FFmpegæ„å¤–åœæ­¢ï¼Œå°è¯•é‡å¯
                        async with self._state_lock:
                            if self._state == "RUNNING":
                                logger.warning("FFmpegæ„å¤–åœæ­¢ï¼Œå°è¯•é‡å¯")
                                await self.ffmpeg_manager.restart()
                    
                    await asyncio.sleep(5)  # æ¯5ç§’æ£€æŸ¥ä¸€æ¬¡
                    
                except asyncio.CancelledError:
                    logger.info("ç›‘æ§ä»»åŠ¡è¢«å–æ¶ˆ")
                    break
                except Exception as e:
                    logger.error(f"ç›‘æ§ä»»åŠ¡é”™è¯¯: {e}")
                    await asyncio.sleep(1)
                    
        except Exception as e:
            logger.error(f"ç›‘æ§ä»»åŠ¡å¼‚å¸¸: {e}")
        finally:
            logger.info("ä»»åŠ¡ç›‘æ§ç»“æŸ")

    async def results_formatter(self) -> AsyncIterator[dict]:
        """ç»“æœæ ¼å¼åŒ–å™¨ - ç”Ÿæˆè½¬å½•ç»“æœæµ"""
        logger.info("å¯åŠ¨ç»“æœæ ¼å¼åŒ–å™¨...")
        
        try:
            while True:
                # æ£€æŸ¥çŠ¶æ€
                async with self._state_lock:
                    current_state = self._state
                
                if current_state != "RUNNING":
                    logger.info(f"çŠ¶æ€å˜ä¸º{current_state}ï¼Œåœæ­¢ç»“æœæ ¼å¼åŒ–")
                    break
                try:
                    # å‘é€çŠ¶æ€æ›´æ–°
                    yield {
                        "status": "processing",
                        "timestamp": time(),
                        "buffer_size": len(self.pcm_buffer)
                    }
                    
                    await asyncio.sleep(0.5)  # æ¯500mså‘é€ä¸€æ¬¡çŠ¶æ€
                    
                except Exception as e:
                    logger.error(f"ç»“æœæ ¼å¼åŒ–å™¨é”™è¯¯: {e}")
                    await asyncio.sleep(1)
                    
        except Exception as e:
            logger.error(f"ç»“æœæ ¼å¼åŒ–å™¨å¼‚å¸¸: {e}")
        finally:
            # å‘é€æœ€ç»ˆçŠ¶æ€
            yield {
                "status": "finished",
                "timestamp": time()
            }
            logger.info("ç»“æœæ ¼å¼åŒ–å™¨ç»“æŸ")

    async def cleanup(self):
        """
        æ¸…ç†èµ„æº - å¹‚ç­‰æ“ä½œ
        
        ã€LinusåŸåˆ™ã€‘ï¼šcleanupå¯ä»¥è¢«å¤šæ¬¡è°ƒç”¨ï¼Œä¸ä¼šå‡ºé”™
        """
        async with self._state_lock:
            if self._state == "STOPPED":
                logger.info("AudioProcessorå·²ç»æ¸…ç†è¿‡ï¼Œè·³è¿‡")
                return
            
            logger.info(f"å¼€å§‹æ¸…ç†AudioProcessorï¼ˆå½“å‰çŠ¶æ€: {self._state}ï¼‰...")
            # çŠ¶æ€è½¬æ¢ -> STOPPED
            self._state = "STOPPED"
        
        # å–æ¶ˆæ‰€æœ‰ä»»åŠ¡
        for task in self.all_tasks_for_cleanup:
            if task and not task.done():
                task.cancel()
        
        # ç­‰å¾…ä»»åŠ¡å®Œæˆ
        created_tasks = [t for t in self.all_tasks_for_cleanup if t]
        if created_tasks:
            await asyncio.gather(*created_tasks, return_exceptions=True)
        logger.info("æ‰€æœ‰å¤„ç†ä»»åŠ¡å·²å–æ¶ˆæˆ–å®Œæˆ")
        
        # åœæ­¢FFmpegç®¡ç†å™¨
        await self.ffmpeg_manager.stop()
        logger.info("FFmpegç®¡ç†å™¨å·²åœæ­¢")
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        for temp_file in self.temp_files:
            try:
                if os.path.exists(temp_file):
                    os.remove(temp_file)
            except Exception as e:
                logger.warning(f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}")
        
        logger.info("AudioProcessoræ¸…ç†å®Œæˆï¼ŒçŠ¶æ€: STOPPED")

    def convert_pcm_to_float(self, pcm_buffer) -> np.ndarray:
        """å°†PCMç¼“å†²åŒºè½¬æ¢ä¸ºæ ‡å‡†åŒ–çš„NumPyæ•°ç»„ï¼ˆæ¥å—bytesæˆ–bytearrayï¼‰"""
        audio_int16 = np.frombuffer(pcm_buffer, dtype=np.int16)
        return audio_int16.astype(np.float32) / 32768.0

    def _transcribe_audio_array(self, audio_array: np.ndarray) -> Optional[dict]:
        """è½¬å½•éŸ³é¢‘æ•°ç»„ - åŒæ­¥æ–¹æ³•"""
        try:
            import datetime
            
            # ç›´æ¥ä½¿ç”¨éŸ³é¢‘æ•°ç»„è¿›è¡Œè½¬å½•
            results = list(self.streaming_service.stream_recognize_chunks(
                audio_chunks=[audio_array],  # å°†å•ä¸ªæ•°ç»„ä½œä¸ºä¸€ä¸ªå—ä¼ å…¥
                sample_rate=self.sample_rate  # ç›´æ¥ä½¿ç”¨å½“å‰çš„é‡‡æ ·ç‡
            ))
            
            if results:
                return {
                    'text': results[-1],
                    'confidence': 0.95,
                    'speaker_id': 'speaker_1',
                    'timestamp': datetime.datetime.now().isoformat(),
                    'is_final': False,
                    'audio_duration': len(audio_array) / self.sample_rate
                }
        except Exception as e:
            logger.error(f"éŸ³é¢‘è½¬å½•å¤±è´¥: {e}")
            return None

    def set_transcription_callback(self, callback: Callable[[dict], None]):
        """è®¾ç½®è½¬å½•ç»“æœå›è°ƒ"""
        self.on_transcription_callback = callback

    def set_error_callback(self, callback: Callable[[str], None]):
        """è®¾ç½®é”™è¯¯å›è°ƒ"""
        self.on_error_callback = callback
    
    def _prepare_audio_file(self, media_path: str) -> Optional[str]:
        """
        å‡†å¤‡éŸ³é¢‘æ–‡ä»¶ï¼Œå¦‚æœæ˜¯è§†é¢‘æ–‡ä»¶åˆ™æå–éŸ³é¢‘
        
        Args:
            media_path: åª’ä½“æ–‡ä»¶è·¯å¾„
            
        Returns:
            éŸ³é¢‘æ–‡ä»¶è·¯å¾„ï¼Œå¤±è´¥è¿”å›None
        """
        if not os.path.exists(media_path):
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {media_path}")
            return None
        
        # è·å–åª’ä½“ä¿¡æ¯
        media_info = MediaProcessor.get_media_info(media_path)
        if not media_info:
            print(f"âŒ æ— æ³•è·å–åª’ä½“æ–‡ä»¶ä¿¡æ¯: {media_path}")
            return None
        
        print(f"ğŸ“ æ–‡ä»¶ä¿¡æ¯:")
        print(f"   ç±»å‹: {media_info['type']}")
        print(f"   æ—¶é•¿: {media_info['duration']:.2f}ç§’")
        print(f"   å¤§å°: {media_info['file_size'] / 1024 / 1024:.2f}MB")
        
        if media_info['type'] == 'audio':
            # éŸ³é¢‘æ–‡ä»¶ç›´æ¥è¿”å›
            print(f"ğŸµ éŸ³é¢‘æ–‡ä»¶ï¼Œç›´æ¥å¤„ç†")
            return media_path
        elif media_info['type'] == 'video':
            # è§†é¢‘æ–‡ä»¶éœ€è¦æå–éŸ³é¢‘
            if not media_info['has_audio']:
                print(f"âŒ è§†é¢‘æ–‡ä»¶ä¸åŒ…å«éŸ³é¢‘æµ")
                return None
            
            print(f"ğŸ¬ è§†é¢‘æ–‡ä»¶ï¼ŒåŒ…å« {media_info['audio_streams']} ä¸ªéŸ³é¢‘æµ")
            
            # æå–éŸ³é¢‘
            audio_path = MediaProcessor.extract_audio_from_video(media_path)
            if audio_path:
                self.temp_files.append(audio_path)  # è®°å½•ä¸´æ—¶æ–‡ä»¶
                print(f"âœ… éŸ³é¢‘æå–å®Œæˆ: {audio_path}")
                return audio_path
            else:
                print(f"âŒ éŸ³é¢‘æå–å¤±è´¥")
                return None
        else:
            print(f"âŒ ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹")
            return None

    def _preprocess_audio(self, media_path: str, enable_denoising: bool = False) -> Optional[str]:
        """
        ç»Ÿä¸€çš„éŸ³é¢‘é¢„å¤„ç†ï¼šæ ¼å¼è½¬æ¢ + å¯é€‰FRCRNé™å™ª
        
        Args:
            media_path: åª’ä½“æ–‡ä»¶è·¯å¾„
            enable_denoising: æ˜¯å¦å¯ç”¨é™å™ª
            
        Returns:
            é¢„å¤„ç†åçš„éŸ³é¢‘æ–‡ä»¶è·¯å¾„ï¼Œå¤±è´¥è¿”å›None
        """
        # 1. ç°æœ‰çš„åª’ä½“æ–‡ä»¶å‡†å¤‡é€»è¾‘
        audio_path = self._prepare_audio_file(media_path)
        if not audio_path:
            return None
        
        # 2. å¯é€‰çš„FRCRNæ¨¡å‹é™å™ªå¤„ç†
        if enable_denoising:
            if self.denoising_service.is_available():
                model_info = self.denoising_service.get_model_info()
                print(f"ğŸ”§ å¯ç”¨é™å™ª: {model_info['model']} ({model_info['type']})")
                
                denoised_path = self.denoising_service.denoise(audio_path)
                if denoised_path and denoised_path != audio_path:
                    print(f"âœ… é™å™ªå¤„ç†å®Œæˆ")
                    return denoised_path
                else:
                    print("âš ï¸ é™å™ªå¤„ç†å¤±è´¥æˆ–æ— æ•ˆæœï¼Œä½¿ç”¨åŸå§‹éŸ³é¢‘")
                    return audio_path
            else:
                print("âš ï¸ é™å™ªæœåŠ¡ä¸å¯ç”¨ï¼Œä½¿ç”¨åŸå§‹éŸ³é¢‘")
                return audio_path
        
        return audio_path

    def process_single_audio(self, 
                           media_path: str, 
                           language: str = "auto",
                           streaming: bool = False) -> Optional[str]:
        """å¤„ç†å•ä¸ªåª’ä½“æ–‡ä»¶ï¼ˆéŸ³é¢‘æˆ–è§†é¢‘ï¼‰- è¯­éŸ³è¯†åˆ«"""
        print(f"\n=== å¤„ç†åª’ä½“æ–‡ä»¶ ===")
        print(f"æ–‡ä»¶: {media_path}")
        print(f"è¯­è¨€: {language}")
        print(f"æ¨¡å¼: {'æµå¼' if streaming else 'ç¦»çº¿'}")
        
        # å‡†å¤‡éŸ³é¢‘æ–‡ä»¶
        audio_path = self._prepare_audio_file(media_path)
        if not audio_path:
            return None
        
        try:
            if streaming:
                # æµå¼è¯†åˆ«
                print("ğŸ”„ å¼€å§‹æµå¼è¯†åˆ«...")
                results = []
                for result in self.streaming_service.stream_recognize_file(audio_path):
                    results.append(result)
                
                # åˆå¹¶æ‰€æœ‰ç»“æœ
                if results:
                    full_text = " ".join([r.split(": ", 1)[1] for r in results if ": " in r])
                    print(f"\nâœ… å®Œæ•´è¯†åˆ«ç»“æœ: {full_text}")
                    return full_text
                return None
            else:
                # ç¦»çº¿è¯†åˆ«
                print("ğŸ”„ å¼€å§‹ç¦»çº¿è¯†åˆ«...")
                result = self.speech_service.recognize_file(
                    audio_path, 
                    language=language
                )
                
                if result:
                    print(f"âœ… è¯†åˆ«ç»“æœ: {result}")
                    return result
                return None
                
        except Exception as e:
            print(f"âŒ è¯†åˆ«å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def separate_speakers(self, 
                         media_path: str, 
                         output_dir: str,
                         merge_threshold: int = 10,
                         save_audio_segments: bool = True,
                         save_merged_audio: bool = True,
                         hotwords: Optional[List[str]] = None,
                         progress_callback: Optional[Callable] = None) -> Dict:
        """
        æ‰§è¡Œè¯´è¯äººåˆ†ç¦»
        
        Args:
            media_path: åª’ä½“æ–‡ä»¶è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•
            merge_threshold: åˆå¹¶ç›¸é‚»ç›¸åŒè¯´è¯äººçš„å­—æ•°é˜ˆå€¼
            save_audio_segments: æ˜¯å¦ä¿å­˜éŸ³é¢‘ç‰‡æ®µ
            save_merged_audio: æ˜¯å¦ä¿å­˜åˆå¹¶çš„éŸ³é¢‘
            hotwords: çƒ­è¯åˆ—è¡¨
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°
            
        Returns:
            åˆ†ç¦»ç»“æœå­—å…¸
        """
        print(f"\n=== è¯´è¯äººåˆ†ç¦» ===")
        print(f"æ–‡ä»¶: {media_path}")
        print(f"è¾“å‡ºç›®å½•: {output_dir}")
        print(f"åˆå¹¶é˜ˆå€¼: {merge_threshold}")
        
        # å‡†å¤‡éŸ³é¢‘æ–‡ä»¶
        audio_path = self._prepare_audio_file(media_path)
        if not audio_path:
            return {'success': False, 'message': 'éŸ³é¢‘æ–‡ä»¶å‡†å¤‡å¤±è´¥'}
        
        try:
            # è®¾ç½®çƒ­è¯
            if hotwords:
                self.speaker_service.set_hotwords(hotwords_list=hotwords)
            
            # æ‰§è¡Œè¯´è¯äººåˆ†ç¦»
            result = self.speaker_service.separate_speakers(
                audio_path, 
                merge_threshold=merge_threshold,
                progress_callback=progress_callback
            )
            
            if result['success']:
                # ä¿å­˜ç»“æœ
                saved_paths = self.speaker_service.save_separation_results(
                    result, 
                    output_dir,
                    save_audio_segments=save_audio_segments,
                    save_merged_audio=save_merged_audio
                )
                result['saved_paths'] = saved_paths
                
                print(f"âœ… è¯´è¯äººåˆ†ç¦»å®Œæˆ")
                print(f"ğŸ“Š ç»“æœ:")
                print(f"   æ£€æµ‹åˆ°è¯´è¯äºº: {len(result['speakers'])} ä¸ª")
                print(f"   æ€»æ—¶é•¿: {result['processing_time']:.2f}ç§’")
                print(f"   ä¿å­˜è·¯å¾„: {saved_paths['base_dir']}")
            
            return result
            
        except Exception as e:
            error_msg = f"è¯´è¯äººåˆ†ç¦»å¤±è´¥: {e}"
            print(f"âŒ {error_msg}")
            import traceback
            traceback.print_exc()
            return {'success': False, 'message': error_msg}
    
    def batch_separate_speakers(self, 
                              media_paths: List[str], 
                              output_dir: str,
                              merge_threshold: int = 10,
                              save_audio_segments: bool = True,
                              save_merged_audio: bool = True,
                              hotwords: Optional[List[str]] = None,
                              progress_callback: Optional[Callable] = None) -> List[Dict]:
        """
        æ‰¹é‡è¯´è¯äººåˆ†ç¦»
        
        Args:
            media_paths: åª’ä½“æ–‡ä»¶è·¯å¾„åˆ—è¡¨
            output_dir: è¾“å‡ºç›®å½•
            merge_threshold: åˆå¹¶é˜ˆå€¼
            save_audio_segments: æ˜¯å¦ä¿å­˜éŸ³é¢‘ç‰‡æ®µ
            save_merged_audio: æ˜¯å¦ä¿å­˜åˆå¹¶çš„éŸ³é¢‘
            hotwords: çƒ­è¯åˆ—è¡¨
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°
            
        Returns:
            å¤„ç†ç»“æœåˆ—è¡¨
        """
        print(f"\n=== æ‰¹é‡è¯´è¯äººåˆ†ç¦» ===")
        print(f"æ–‡ä»¶æ•°é‡: {len(media_paths)}")
        print(f"è¾“å‡ºç›®å½•: {output_dir}")
        
        # å‡†å¤‡éŸ³é¢‘æ–‡ä»¶åˆ—è¡¨
        audio_files = []
        for media_path in media_paths:
            audio_path = self._prepare_audio_file(media_path)
            if audio_path:
                audio_files.append(audio_path)
            else:
                print(f"âš ï¸ è·³è¿‡æ— æ•ˆæ–‡ä»¶: {media_path}")
        
        if not audio_files:
            return [{'success': False, 'message': 'æ²¡æœ‰æœ‰æ•ˆçš„éŸ³é¢‘æ–‡ä»¶'}]
        
        try:
            # è®¾ç½®çƒ­è¯
            if hotwords:
                self.speaker_service.set_hotwords(hotwords_list=hotwords)
            
            # æ‰§è¡Œæ‰¹é‡å¤„ç†
            results = self.speaker_service.batch_separate_speakers(
                audio_files,
                output_dir,
                merge_threshold=merge_threshold,
                progress_callback=progress_callback
            )
            
            # ç»Ÿè®¡ç»“æœ
            success_count = sum(1 for r in results if r.get('success', False))
            print(f"âœ… æ‰¹é‡å¤„ç†å®Œæˆ: {success_count}/{len(results)} ä¸ªæ–‡ä»¶æˆåŠŸ")
            
            return results
            
        except Exception as e:
            error_msg = f"æ‰¹é‡å¤„ç†å¤±è´¥: {e}"
            print(f"âŒ {error_msg}")
            import traceback
            traceback.print_exc()
            return [{'success': False, 'message': error_msg}]
    
    def compare_modes(self, media_path: str, language: str = "auto") -> Dict:
        """æ¯”è¾ƒç¦»çº¿å’Œæµå¼æ¨¡å¼"""
        print(f"\n=== æ¨¡å¼å¯¹æ¯” ===")
        print(f"æ–‡ä»¶: {media_path}")
        
        results = {
            'offline': None,
            'streaming': None,
            'offline_time': 0,
            'streaming_time': 0
        }
        
        import time
        
        # ç¦»çº¿æ¨¡å¼
        print("\nğŸ”„ æµ‹è¯•ç¦»çº¿æ¨¡å¼...")
        start_time = time.time()
        results['offline'] = self.process_single_audio(media_path, language, streaming=False)
        results['offline_time'] = time.time() - start_time
        
        # æµå¼æ¨¡å¼
        print("\nğŸ”„ æµ‹è¯•æµå¼æ¨¡å¼...")
        start_time = time.time()
        results['streaming'] = self.process_single_audio(media_path, language, streaming=True)
        results['streaming_time'] = time.time() - start_time
        
        # æ˜¾ç¤ºå¯¹æ¯”ç»“æœ
        print(f"\nğŸ“Š å¯¹æ¯”ç»“æœ:")
        print(f"ç¦»çº¿æ¨¡å¼: {results['offline']} (è€—æ—¶: {results['offline_time']:.2f}ç§’)")
        print(f"æµå¼æ¨¡å¼: {results['streaming']} (è€—æ—¶: {results['streaming_time']:.2f}ç§’)")
        
        return results
    
    def analyze_audio_with_all_features(self, 
                                      media_path: str, 
                                      output_dir: str,
                                      language: str = "auto",
                                      merge_threshold: int = 10,
                                      hotwords: Optional[List[str]] = None,
                                      enable_denoising: bool = False) -> Dict:
        """
        åˆ†æéŸ³é¢‘ï¼šè¯­éŸ³è¯†åˆ« + è¯´è¯äººåˆ†ç¦»
        
        Args:
            media_path: åª’ä½“æ–‡ä»¶è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•
            language: è¯­è¨€è®¾ç½®
            merge_threshold: åˆå¹¶é˜ˆå€¼
            hotwords: çƒ­è¯åˆ—è¡¨
            
        Returns:
            å®Œæ•´åˆ†æç»“æœ
        """
        print(f"\n=== å®Œæ•´éŸ³é¢‘åˆ†æ ===")
        print(f"æ–‡ä»¶: {media_path}")
        
        results = {
            'speech_recognition': None,
            'speaker_separation': None,
            'success': False,
            'message': ''
        }
        
        try:
             # è®°å½•é™å™ªæ¨¡å‹ä¿¡æ¯
            if enable_denoising:
                results['denoising_model'] = self.denoising_service.get_model_info()

            # 1. ç»Ÿä¸€éŸ³é¢‘é¢„å¤„ç†ï¼ˆåŒ…å«å¯é€‰FRCRNé™å™ªï¼‰
            processed_audio = self._preprocess_audio(media_path, enable_denoising)
            if not processed_audio:
                results['message'] = 'éŸ³é¢‘é¢„å¤„ç†å¤±è´¥'
                return results

            # 1. æ‰§è¡Œè¯­éŸ³è¯†åˆ«
            print("\nğŸ”„ æ‰§è¡Œè¯­éŸ³è¯†åˆ«...")
            speech_result = self.process_single_audio(processed_audio, language)
            results['speech_recognition'] = speech_result
            
            # 2. æ‰§è¡Œè¯´è¯äººåˆ†ç¦»
            print("\nğŸ”„ æ‰§è¡Œè¯´è¯äººåˆ†ç¦»...")
            speaker_result = self.separate_speakers(
                processed_audio, 
                output_dir,
                merge_threshold=merge_threshold,
                hotwords=hotwords
            )
            results['speaker_separation'] = speaker_result
            
            if speech_result or speaker_result.get('success', False):
                results['success'] = True
                results['message'] = 'éŸ³é¢‘åˆ†æå®Œæˆ'
            else:
                results['message'] = 'éŸ³é¢‘åˆ†æå¤±è´¥'
            
            return results
            
        except Exception as e:
            error_msg = f"å®Œæ•´åˆ†æå¤±è´¥: {e}"
            print(f"âŒ {error_msg}")
            results['message'] = error_msg
            return results
    
    async def prepare_streaming_models(self) -> bool:
        """å‡†å¤‡æ¨¡å‹ - å¼‚æ­¥åŠ è½½"""
        try:
            logger.info("å¼€å§‹å‡†å¤‡æµå¼è½¬å½•æ¨¡å‹...")
            
            if hasattr(self, 'streaming_service') and self.streaming_service:
                success = await asyncio.get_event_loop().run_in_executor(
                    None, 
                    self.streaming_service._prepare_streaming_model
                )
                if not success:
                    logger.error("æµå¼æ¨¡å‹å‡†å¤‡å¤±è´¥")
                    return False
            
            # æ¨¡æ‹Ÿé¢å¤–çš„å‡†å¤‡æ—¶é—´
            await asyncio.sleep(1)
            
            logger.info("æ¨¡å‹å‡†å¤‡å®Œæˆ")
            return True
            
        except Exception as e:
            logger.error(f"æ¨¡å‹å‡†å¤‡å¤±è´¥: {e}")
            return False
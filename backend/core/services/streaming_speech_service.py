import os
import numpy as np
from typing import Optional, Generator, Callable, Union
import soundfile
import torch
import torchaudio
from core.utils.model_manager import ModelManager

class StreamingSpeechService:
    """æµå¼è¯­éŸ³è¯†åˆ«æœåŠ¡"""
    
    def __init__(self, model_manager: ModelManager):
        self.model_manager = model_manager
        self.cache = {}
        self.current_model = None
        self.streaming_config = None
    
    def _prepare_streaming_model(self, model_name: str = "paraformer-zh-streaming") -> bool:
        """å‡†å¤‡æµå¼æ¨¡å‹"""
        try:
            self.current_model = self.model_manager.get_model(model_name)
            if not self.current_model:
                print(f"âŒ æ— æ³•åŠ è½½æµå¼æ¨¡å‹: {model_name}")
                return False
            
            # è·å–æµå¼é…ç½®
            self.streaming_config = self.model_manager.model_config.get_streaming_config(model_name)
            if not self.streaming_config:
                print(f"âŒ æ— æ³•è·å–æµå¼é…ç½®: {model_name}")
                return False
            
            # é‡ç½®ç¼“å­˜
            self.cache = {}
            print(f"âœ“ æµå¼æ¨¡å‹å‡†å¤‡å®Œæˆ: {model_name}")
            return True
            
        except Exception as e:
            print(f"âŒ å‡†å¤‡æµå¼æ¨¡å‹å¤±è´¥: {e}")
            return False
    
    def _calculate_chunk_stride(self, sample_rate: int = 16000) -> int:
        """è®¡ç®—å—æ­¥é•¿"""
        chunk_stride_ms = self.streaming_config.get("chunk_stride_ms", 600)
        return int(chunk_stride_ms * sample_rate / 1000)  # è½¬æ¢ä¸ºé‡‡æ ·ç‚¹æ•°

    def _resample_audio(self, speech: np.ndarray, original_sr: int, target_sr: int = 16000) -> np.ndarray:
        """
        ä½¿ç”¨FunASRçš„é‡é‡‡æ ·åŠŸèƒ½é‡é‡‡æ ·éŸ³é¢‘
        
        Args:
            speech: éŸ³é¢‘æ•°æ®
            original_sr: åŸå§‹é‡‡æ ·ç‡
            target_sr: ç›®æ ‡é‡‡æ ·ç‡
            
        Returns:
            é‡é‡‡æ ·åçš„éŸ³é¢‘æ•°æ®
        """
        if original_sr == target_sr:
            return speech
            
        try:
            print(f"ğŸ”„ ä½¿ç”¨FunASRé‡é‡‡æ ·åŠŸèƒ½: {original_sr}Hz -> {target_sr}Hz")
            
            # è½¬æ¢ä¸ºtorch tensor
            speech_tensor = torch.from_numpy(speech)
            
            # ä½¿ç”¨torchaudioçš„é‡é‡‡æ ·å™¨
            resampler = torchaudio.transforms.Resample(original_sr, target_sr)
            
            # é‡é‡‡æ · (éœ€è¦æ·»åŠ batchç»´åº¦)
            if speech_tensor.dim() == 1:
                resampled = resampler(speech_tensor.unsqueeze(0)).squeeze(0)
            else:
                resampled = resampler(speech_tensor)
            
            # è½¬æ¢å›numpy
            resampled_audio = resampled.numpy()
            
            print(f"âœ… é‡é‡‡æ ·å®Œæˆ: é•¿åº¦ {len(speech)} -> {len(resampled_audio)}")
            return resampled_audio
            
        except Exception as e:
            print(f"âŒ é‡é‡‡æ ·å¤±è´¥: {e}")
            print("âš ï¸ å°†ç»§ç»­ä½¿ç”¨åŸå§‹éŸ³é¢‘ï¼Œä½†å¯èƒ½å½±å“è¯†åˆ«æ•ˆæœ")
            return speech
    
    def stream_recognize_file(self, 
                            audio_file: str, 
                            model_name: str = "paraformer-zh-streaming",
                            callback: Optional[Callable] = None) -> Generator[str, None, None]:
        """
        æµå¼è¯†åˆ«éŸ³é¢‘æ–‡ä»¶
        
        Args:
            audio_file: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            model_name: æ¨¡å‹åç§°
            callback: ç»“æœå›è°ƒå‡½æ•°
        
        Yields:
            è¯†åˆ«ç»“æœ
        """
        if not os.path.exists(audio_file):
            raise FileNotFoundError(f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_file}")
        
        # å‡†å¤‡æ¨¡å‹
        if not self._prepare_streaming_model(model_name):
            return
        
        try:
            # è¯»å–éŸ³é¢‘æ–‡ä»¶
            speech, sample_rate = soundfile.read(audio_file)
            print(f"éŸ³é¢‘æ–‡ä»¶: {audio_file}")
            print(f"é‡‡æ ·ç‡: {sample_rate}, æ—¶é•¿: {len(speech)/sample_rate:.2f}ç§’")
            
            # å¦‚æœé‡‡æ ·ç‡ä¸æ˜¯16kHzï¼Œéœ€è¦é‡é‡‡æ ·
            if sample_rate != 16000:
                print("âš ï¸ éŸ³é¢‘é‡‡æ ·ç‡ä¸æ˜¯16kHzï¼Œæ­£åœ¨è¿›è¡Œé‡é‡‡æ ·...")
                speech = self._resample_audio(speech, sample_rate, 16000)
                sample_rate = 16000
                print(f"âœ… é‡é‡‡æ ·å®Œæˆï¼Œæ–°é‡‡æ ·ç‡: {sample_rate}Hz, æ–°æ—¶é•¿: {len(speech)/sample_rate:.2f}ç§’")

            
            chunk_stride = self._calculate_chunk_stride(sample_rate)
            total_chunk_num = int((len(speech) - 1) / chunk_stride + 1)
            
            print(f"å¼€å§‹æµå¼è¯†åˆ«(file)ï¼Œå…± {total_chunk_num} ä¸ªå—")
            
            for i in range(total_chunk_num):
                # æå–éŸ³é¢‘å—
                start_idx = i * chunk_stride
                end_idx = min((i + 1) * chunk_stride, len(speech))
                speech_chunk = speech[start_idx:end_idx]
                
                # æ˜¯å¦ä¸ºæœ€åä¸€å—
                is_final = i == total_chunk_num - 1
                
                # æ‰§è¡Œè¯†åˆ«
                res = self.current_model.generate(
                    input=speech_chunk,
                    cache=self.cache,
                    is_final=is_final,
                    chunk_size=self.streaming_config["chunk_size"],
                    encoder_chunk_look_back=self.streaming_config["encoder_chunk_look_back"],
                    decoder_chunk_look_back=self.streaming_config["decoder_chunk_look_back"]
                )
                
                # å¤„ç†ç»“æœ
                if res and len(res) > 0:
                    text = res[0].get("text", "")
                    if text.strip():
                        result = f"å— {i+1}/{total_chunk_num}: {text}"
                        print(result)
                        
                        # è°ƒç”¨å›è°ƒå‡½æ•°
                        if callback:
                            callback(i, total_chunk_num, text, is_final)
                        
                        yield text
                
        except Exception as e:
            print(f"âŒ æµå¼è¯†åˆ«å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    def stream_recognize_chunks(self, 
                              audio_chunks: list, 
                              model_name: str = "paraformer-zh-streaming",
                              sample_rate: int = 16000) -> Generator[str, None, None]:
        """
        æµå¼è¯†åˆ«éŸ³é¢‘å—åºåˆ—
        
        Args:
            audio_chunks: éŸ³é¢‘å—åˆ—è¡¨
            model_name: æ¨¡å‹åç§°
            sample_rate: é‡‡æ ·ç‡
        
        Yields:
            è¯†åˆ«ç»“æœ
        """
        # å‡†å¤‡æ¨¡å‹
        if not self._prepare_streaming_model(model_name):
            return
        
        # æ£€æŸ¥é‡‡æ ·ç‡å¹¶é‡é‡‡æ ·éŸ³é¢‘å—
        if sample_rate != 16000:
            print(f"âš ï¸ éŸ³é¢‘å—é‡‡æ ·ç‡ä¸æ˜¯16kHz ({sample_rate}Hz)ï¼Œæ­£åœ¨é‡é‡‡æ ·...")
            resampled_chunks = []
            for i, chunk in enumerate(audio_chunks):
                resampled_chunk = self._resample_audio(chunk, sample_rate, 16000)
                resampled_chunks.append(resampled_chunk)
            audio_chunks = resampled_chunks
            sample_rate = 16000
            print(f"âœ… æ‰€æœ‰éŸ³é¢‘å—é‡é‡‡æ ·å®Œæˆ")
        
        total_chunks = len(audio_chunks)
        print(f"å¼€å§‹æµå¼è¯†åˆ«(chunks)ï¼Œå…± {total_chunks} ä¸ªå—")
        
        try:
            for i, chunk in enumerate(audio_chunks):
                is_final = i == total_chunks - 1
                
                # æ‰§è¡Œè¯†åˆ«
                res = self.current_model.generate(
                    input=chunk,
                    cache=self.cache,
                    is_final=is_final,
                    chunk_size=self.streaming_config["chunk_size"],
                    encoder_chunk_look_back=self.streaming_config["encoder_chunk_look_back"],
                    decoder_chunk_look_back=self.streaming_config["decoder_chunk_look_back"]
                )
                
                # å¤„ç†ç»“æœ
                if res and len(res) > 0:
                    text = res[0].get("text", "")
                    if text.strip():
                        result = f"å— {i+1}/{total_chunks}: {text}"
                        print(result)
                        yield text
                        
        except Exception as e:
            print(f"âŒ æµå¼è¯†åˆ«å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    def reset_cache(self):
        """é‡ç½®ç¼“å­˜"""
        self.cache = {}
        print("âœ“ ç¼“å­˜å·²é‡ç½®")
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è¯´è¯äººåˆ†ç¦»åŠŸèƒ½æ¼”ç¤ºè„šæœ¬
"""

import os
from typing import Optional, Dict, List
from services.audio_processor import AudioProcessor
from utils.download_manager import DownloadManager
from config.model_config import ModelConfig  # æ·»åŠ è¿™è¡Œå¯¼å…¥

def progress_callback(message: str, progress: int):
    """è¿›åº¦å›è°ƒå‡½æ•°"""
    if progress >= 0:
        print(f"[{progress:3d}%] {message}")
    else:
        print(f"[ERROR] {message}")

def _select_audio_file(audio_files: List[str]) -> Optional[str]:
    """
    é€‰æ‹©éŸ³é¢‘æ–‡ä»¶çš„è¾…åŠ©å‡½æ•°
    
    Args:
        audio_files: éŸ³é¢‘æ–‡ä»¶åˆ—è¡¨
        
    Returns:
        é€‰ä¸­çš„éŸ³é¢‘æ–‡ä»¶è·¯å¾„ï¼Œå–æ¶ˆæˆ–é”™è¯¯è¿”å›None
    """
    if len(audio_files) == 1:
        # åªæœ‰ä¸€ä¸ªæ–‡ä»¶ï¼Œç›´æ¥è¿”å›
        return audio_files[0]
    
    print("\nè¯·é€‰æ‹©è¦å¤„ç†çš„æ–‡ä»¶:")
    for i, file in enumerate(audio_files, 1):
        file_name = os.path.basename(file)
        file_size = os.path.getsize(file) / (1024 * 1024)  # MB
        print(f"   {i}. {file_name} ({file_size:.1f}MB)")
    
    try:
        while True:
            file_choice = input(f"\nè¯·è¾“å…¥æ–‡ä»¶ç¼–å· (1-{len(audio_files)}): ").strip()
            
            if not file_choice:
                print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ–‡ä»¶ç¼–å·")
                continue
                
            try:
                choice_idx = int(file_choice) - 1
                if 0 <= choice_idx < len(audio_files):
                    selected_file = audio_files[choice_idx]
                    print(f"âœ… å·²é€‰æ‹©: {os.path.basename(selected_file)}")
                    return selected_file
                else:
                    print(f"âŒ ç¼–å·è¶…å‡ºèŒƒå›´ï¼Œè¯·è¾“å…¥ 1-{len(audio_files)} ä¹‹é—´çš„æ•°å­—")
            except ValueError:
                print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
                
    except KeyboardInterrupt:
        print("\nğŸ‘‹ ç”¨æˆ·å–æ¶ˆé€‰æ‹©")
        return None
    except Exception as e:
        print(f"âŒ é€‰æ‹©æ–‡ä»¶æ—¶å‡ºé”™: {e}")
        return None

def _print_analysis_result(result: Dict):
    """
    æ‰“å°å®Œæ•´åˆ†æç»“æœçš„è¾…åŠ©å‡½æ•°
    
    Args:
        result: åˆ†æç»“æœå­—å…¸
    """
    if result.get('success', False):
        print(f"\nâœ… å®Œæ•´åˆ†æå®Œæˆ!")
        
        # æ˜¾ç¤ºé™å™ªçŠ¶æ€å’Œæ¨¡å‹ä¿¡æ¯
        if result.get('denoising_enabled', False):
            denoising_model = result.get('denoising_model', {})
            model_name = denoising_model.get('model', 'Unknown')
            model_type = denoising_model.get('type', 'Unknown')
            model_status = denoising_model.get('status', 'unknown')
            
            if model_status == 'ready':
                print(f"ğŸ”§ é™å™ªæ¨¡å‹: {model_name} ({model_type})")
            elif model_status == 'fallback':
                print(f"ğŸ”§ é™å™ªæ–¹æ³•: {model_name} (FRCRNæ¨¡å‹ä¸å¯ç”¨æ—¶çš„å›é€€æ–¹æ¡ˆ)")
            else:
                print(f"ğŸ”§ é™å™ª: å·²å¯ç”¨ä½†çŠ¶æ€æœªçŸ¥")
        else:
            print("ğŸ”§ é™å™ª: æœªå¯ç”¨")
        
        # æ˜¾ç¤ºè¯­éŸ³è¯†åˆ«ç»“æœ
        speech_result = result.get('speech_recognition')
        if speech_result:
            # æ™ºèƒ½æˆªå–é¢„è§ˆæ–‡æœ¬
            preview_length = 100
            if len(speech_result) > preview_length:
                text_preview = speech_result[:preview_length] + "..."
                full_length = len(speech_result)
                print(f"ğŸ¤ è¯­éŸ³è¯†åˆ«ç»“æœ ({full_length}å­—ç¬¦): {text_preview}")
            else:
                print(f"ğŸ¤ è¯­éŸ³è¯†åˆ«ç»“æœ: {speech_result}")
        else:
            print("ğŸ¤ è¯­éŸ³è¯†åˆ«: æ— ç»“æœ")
        
        # æ˜¾ç¤ºè¯´è¯äººåˆ†ç¦»ç»“æœ
        speaker_result = result.get('speaker_separation')
        if speaker_result and speaker_result.get('success', False):
            speakers = speaker_result.get('speakers', [])
            speaker_count = len(speakers)
            print(f"ğŸ‘¥ è¯´è¯äººåˆ†ç¦»: æ£€æµ‹åˆ° {speaker_count} ä¸ªè¯´è¯äºº")
            
            # æ˜¾ç¤ºæ¯ä¸ªè¯´è¯äººçš„ç®€è¦ä¿¡æ¯
            for i, speaker in enumerate(speakers[:3], 1):  # æœ€å¤šæ˜¾ç¤ºå‰3ä¸ª
                duration = speaker.get('total_duration', 0)
                segment_count = len(speaker.get('segments', []))
                print(f"   è¯´è¯äºº{i}: {duration:.1f}ç§’, {segment_count}ä¸ªç‰‡æ®µ")
            
            if len(speakers) > 3:
                print(f"   ...è¿˜æœ‰{len(speakers) - 3}ä¸ªè¯´è¯äºº")
            
            # æ˜¾ç¤ºä¿å­˜è·¯å¾„
            saved_paths = speaker_result.get('saved_paths', {})
            base_dir = saved_paths.get('base_dir')
            if base_dir:
                print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {base_dir}")
                
                # æ˜¾ç¤ºä¸»è¦è¾“å‡ºæ–‡ä»¶
                if 'summary_file' in saved_paths:
                    print(f"   ğŸ“„ åˆ†ææŠ¥å‘Š: {os.path.basename(saved_paths['summary_file'])}")
                if 'merged_audio_files' in saved_paths:
                    merged_files = saved_paths['merged_audio_files']
                    if merged_files:
                        print(f"   ğŸµ åˆå¹¶éŸ³é¢‘: {len(merged_files)}ä¸ªæ–‡ä»¶")
        else:
            speaker_error = speaker_result.get('message', 'æœªçŸ¥é”™è¯¯') if speaker_result else 'æ— ç»“æœ'
            print(f"ğŸ‘¥ è¯´è¯äººåˆ†ç¦»: å¤±è´¥ ({speaker_error})")
        
        # æ˜¾ç¤ºå¤„ç†ä¿¡æ¯
        message = result.get('message', '')
        if message and message != 'éŸ³é¢‘åˆ†æå®Œæˆ':
            print(f"ğŸ’¬ å¤„ç†ä¿¡æ¯: {message}")
            
    else:
        # åˆ†æå¤±è´¥
        error_message = result.get('message', 'æœªçŸ¥é”™è¯¯')
        print(f"\nâŒ åˆ†æå¤±è´¥: {error_message}")
        
        # å¦‚æœæœ‰éƒ¨åˆ†ç»“æœï¼Œä¹Ÿæ˜¾ç¤ºå‡ºæ¥
        if result.get('speech_recognition'):
            print(f"ğŸ¤ è¯­éŸ³è¯†åˆ«(éƒ¨åˆ†): {result['speech_recognition'][:50]}...")
        
        if result.get('speaker_separation'):
            speaker_msg = result['speaker_separation'].get('message', '')
            if speaker_msg:
                print(f"ğŸ‘¥ è¯´è¯äººåˆ†ç¦»é”™è¯¯: {speaker_msg}")


def demo_speaker_separation():
    """æ¼”ç¤ºè¯´è¯äººåˆ†ç¦»åŠŸèƒ½"""
    print("=== DotVoice è¯´è¯äººåˆ†ç¦»åŠŸèƒ½æ¼”ç¤º ===\n")
    
    # 1. æ£€æŸ¥å¹¶ä¸‹è½½æ¨¡å‹
    print("ğŸ”„ æ£€æŸ¥è¯´è¯äººåˆ†ç¦»æ¨¡å‹...")
    model_config = ModelConfig()  # åˆ›å»º ModelConfig å®ä¾‹
    download_manager = DownloadManager(model_config)  # ä¼ å…¥ ModelConfig å®ä¾‹
    
    # ä¸‹è½½æ¨¡å‹å¹¶æ£€æŸ¥ç»“æœ
    results = download_manager.download_speaker_separation_models()
    if not all(success for _, success, _ in results):
        print("âŒ éƒ¨åˆ†æ¨¡å‹ä¸‹è½½å¤±è´¥:")
        for model_name, success, message in results:
            if not success:
                print(f"   - {model_name}: {message}")
        return
    
    print("âœ… æ‰€æœ‰å¿…éœ€æ¨¡å‹ä¸‹è½½å®Œæˆ")
    
    # 2. åˆå§‹åŒ–å¤„ç†å™¨
    print("\nğŸ”„ åˆå§‹åŒ–éŸ³é¢‘å¤„ç†å™¨...")
    try:
        processor = AudioProcessor()
        print("âœ… éŸ³é¢‘å¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ")
    except Exception as e:
        print(f"âŒ åˆå§‹åŒ–å¤±è´¥: {e}")
        return
    
    # 3. æŸ¥æ‰¾ç¤ºä¾‹éŸ³é¢‘æ–‡ä»¶
    project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    example_dir = os.path.join(project_root, "example")
    
    if not os.path.exists(example_dir):
        print(f"âŒ ç¤ºä¾‹ç›®å½•ä¸å­˜åœ¨: {example_dir}")
        print("ğŸ’¡ è¯·åœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»º example æ–‡ä»¶å¤¹å¹¶æ”¾å…¥éŸ³é¢‘æ–‡ä»¶")
        return
    
    # æŸ¥æ‰¾éŸ³é¢‘æ–‡ä»¶
    audio_files = []
    for file in os.listdir(example_dir):
        if file.lower().endswith(('.mp3', '.wav', '.m4a', '.flac', '.aac', '.mp4', '.avi', '.mov')):
            audio_files.append(os.path.join(example_dir, file))
    
    if not audio_files:
        print(f"âŒ åœ¨ {example_dir} ä¸­æ²¡æœ‰æ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶")
        return
    
    print(f"\nğŸ“ æ‰¾åˆ° {len(audio_files)} ä¸ªåª’ä½“æ–‡ä»¶:")
    for i, file in enumerate(audio_files, 1):
        print(f"   {i}. {os.path.basename(file)}")
    
    # 4. é€‰æ‹©å¤„ç†æ–¹å¼
    print("\nè¯·é€‰æ‹©å¤„ç†æ–¹å¼:")
    print("1. å•æ–‡ä»¶è¯´è¯äººåˆ†ç¦»")
    print("2. æ‰¹é‡è¯´è¯äººåˆ†ç¦»")
    print("3. å®Œæ•´éŸ³é¢‘åˆ†æï¼ˆè¯­éŸ³è¯†åˆ« + è¯´è¯äººåˆ†ç¦»ï¼‰")
    print("4. å®Œæ•´éŸ³é¢‘åˆ†æï¼ˆè¯­éŸ³è¯†åˆ« + è¯´è¯äººåˆ†ç¦»ï¼‰ + FRCRNæ¨¡å‹é™å™ªï¼ˆæ¨èç”¨äºå˜ˆæ‚ç¯å¢ƒï¼‰")
    print("5. é€€å‡º")
    
    try:
        choice = input("\nè¯·è¾“å…¥é€‰æ‹© (1-4): ").strip()
    except KeyboardInterrupt:
        print("\nğŸ‘‹ ç”¨æˆ·å–æ¶ˆæ“ä½œ")
        return
    
    # è®¾ç½®è¾“å‡ºç›®å½•
    output_dir = os.path.join(project_root, "output", "speaker_separation")
    os.makedirs(output_dir, exist_ok=True)
    
    # è®¾ç½®çƒ­è¯ï¼ˆå¯é€‰ï¼‰
    hotwords = ["AI", "zabbix", "snmp"]  # ç¤ºä¾‹çƒ­è¯
    
    try:
        if choice == "1":
            # å•æ–‡ä»¶å¤„ç†
            if len(audio_files) == 1:
                audio_file = audio_files[0]
            else:
                print("\nè¯·é€‰æ‹©è¦å¤„ç†çš„æ–‡ä»¶:")
                for i, file in enumerate(audio_files, 1):
                    print(f"   {i}. {os.path.basename(file)}")
                
                file_choice = int(input("è¯·è¾“å…¥æ–‡ä»¶ç¼–å·: ")) - 1
                if 0 <= file_choice < len(audio_files):
                    audio_file = audio_files[file_choice]
                else:
                    print("âŒ æ— æ•ˆçš„æ–‡ä»¶ç¼–å·")
                    return
            
            print(f"\nğŸ”„ å¤„ç†æ–‡ä»¶: {os.path.basename(audio_file)}")
            result = processor.separate_speakers(
                audio_file,
                output_dir,
                merge_threshold=10,
                save_audio_segments=True,
                save_merged_audio=True,
                hotwords=hotwords,
                progress_callback=progress_callback
            )
            
            if result['success']:
                print(f"\nâœ… å¤„ç†å®Œæˆ!")
                print(f"ğŸ“Š æ£€æµ‹åˆ° {len(result['speakers'])} ä¸ªè¯´è¯äºº")
                print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {result['saved_paths']['base_dir']}")
            else:
                print(f"\nâŒ å¤„ç†å¤±è´¥: {result['message']}")
        
        elif choice == "2":
            # æ‰¹é‡å¤„ç†
            print(f"\nğŸ”„ æ‰¹é‡å¤„ç† {len(audio_files)} ä¸ªæ–‡ä»¶...")
            results = processor.batch_separate_speakers(
                audio_files,
                output_dir,
                merge_threshold=10,
                save_audio_segments=True,
                save_merged_audio=True,
                hotwords=hotwords,
                progress_callback=progress_callback
            )
            
            success_count = sum(1 for r in results if r.get('success', False))
            print(f"\nâœ… æ‰¹é‡å¤„ç†å®Œæˆ: {success_count}/{len(results)} ä¸ªæ–‡ä»¶æˆåŠŸ")
            print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {output_dir}")
        
        elif choice == "3":
            # å®Œæ•´åˆ†æ
            if len(audio_files) == 1:
                audio_file = audio_files[0]
            else:
                print("\nè¯·é€‰æ‹©è¦åˆ†æçš„æ–‡ä»¶:")
                for i, file in enumerate(audio_files, 1):
                    print(f"   {i}. {os.path.basename(file)}")
                
                file_choice = int(input("è¯·è¾“å…¥æ–‡ä»¶ç¼–å·: ")) - 1
                if 0 <= file_choice < len(audio_files):
                    audio_file = audio_files[file_choice]
                else:
                    print("âŒ æ— æ•ˆçš„æ–‡ä»¶ç¼–å·")
                    return
            
            print(f"\nğŸ”„ å®Œæ•´åˆ†ææ–‡ä»¶: {os.path.basename(audio_file)}")
            result = processor.analyze_audio_with_all_features(
                audio_file,
                output_dir,
                language="auto",
                merge_threshold=10,
                hotwords=hotwords
            )
            
            if result['success']:
                print(f"\nâœ… å®Œæ•´åˆ†æå®Œæˆ!")
                if result['speech_recognition']:
                    print(f"ğŸ¤ è¯­éŸ³è¯†åˆ«ç»“æœ: {result['speech_recognition'][:100]}...")
                if result['speaker_separation'] and result['speaker_separation']['success']:
                    print(f"ğŸ‘¥ è¯´è¯äººåˆ†ç¦»: æ£€æµ‹åˆ° {len(result['speaker_separation']['speakers'])} ä¸ªè¯´è¯äºº")
                    print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {result['speaker_separation']['saved_paths']['base_dir']}")
            else:
                print(f"\nâŒ åˆ†æå¤±è´¥: {result['message']}")
        
        elif choice == "4":
            # å®Œæ•´åˆ†æï¼ˆå¯ç”¨FRCRNé™å™ªï¼‰
            audio_file = _select_audio_file(audio_files)
            if not audio_file:
                return
            
            print(f"\nğŸ”„ å®Œæ•´åˆ†ææ–‡ä»¶ï¼ˆå¯ç”¨FRCRNé™å™ªï¼‰: {os.path.basename(audio_file)}")
            print("ğŸ’¡ FRCRNæ¨¡å‹èƒ½æœ‰æ•ˆå»é™¤èƒŒæ™¯å™ªå£°ï¼Œæå‡è¯­éŸ³è¯†åˆ«å‡†ç¡®ç‡")
            print("â±ï¸  é™å™ªå¤„ç†å¯èƒ½éœ€è¦é¢å¤–æ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…...")
            
            result = processor.analyze_audio_with_all_features(
                audio_file,
                output_dir,
                language="auto",
                merge_threshold=10,
                hotwords=hotwords,
                enable_denoising=True  # å¯ç”¨FRCRNé™å™ª
            )
            
            _print_analysis_result(result)

        elif choice == "5":
            print("ğŸ‘‹ é€€å‡ºç¨‹åº")
            return
        
        else:
            print("âŒ æ— æ•ˆçš„é€‰æ‹©")
            return
    
    except (ValueError, IndexError):
        print("âŒ è¾“å…¥æ— æ•ˆ")
        return
    except Exception as e:
        print(f"âŒ å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
    finally:
        # æ¸…ç†èµ„æº
        processor.cleanup()

if __name__ == "__main__":
    demo_speaker_separation()